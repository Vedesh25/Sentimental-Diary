{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:57:56.649014Z",
     "start_time": "2024-11-24T17:57:56.637697Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Analysis on Tweets Dataset for Diary Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:57:57.331446Z",
     "start_time": "2024-11-24T17:57:56.713817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "  text = text.lower()\n",
    "  text = contractions.fix(text)\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "  text = ''.join([i for i in text if not i.isdigit()])\n",
    "  text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "  text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "  text = ' '.join(text.split())\n",
    "  return text"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Loading the Dataset:\n",
    "\n",
    "The data is imported from kaggle: https://www.kaggle.com/datasets/aadyasingh55/twitter-emotion-classification-dataset/data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 25,
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('./export_1731170924611.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:57:57.342263Z",
     "start_time": "2024-11-24T17:57:57.333461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i feel awful about it too because it s my job ...      0\n",
       "1                              im alone i feel awful      0\n",
       "2  ive probably mentioned this before but i reall...      1\n",
       "3           i was feeling a little low few days back      0\n",
       "4  i beleive that i am much more sensitive to oth...      2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:57:57.371790Z",
     "start_time": "2024-11-24T17:57:57.343784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416809 entries, 0 to 416808\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    416809 non-null  object\n",
      " 1   label   416809 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Null & Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:57:57.659888Z",
     "start_time": "2024-11-24T17:57:57.373812Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data after handling pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:57:57.698164Z",
     "start_time": "2024-11-24T17:57:57.661419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 416123 entries, 0 to 416808\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    416123 non-null  object\n",
      " 1   label   416123 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:58:22.203452Z",
     "start_time": "2024-11-24T17:57:57.700277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = df['cleaned_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Encoding : CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:58:26.503211Z",
     "start_time": "2024-11-24T17:58:22.203452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert text data to numerical data using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_count = vectorizer.fit_transform(X_train)\n",
    "X_test_count = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:58:26.511168Z",
     "start_time": "2024-11-24T17:58:26.503637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60514"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Encoding : TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:58:31.027922Z",
     "start_time": "2024-11-24T17:58:26.512973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert text data to numerical data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:58:31.035559Z",
     "start_time": "2024-11-24T17:58:31.030458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60514"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Multinomial Naive Bayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:58:31.156091Z",
     "start_time": "2024-11-24T17:58:31.036866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     24360\n",
      "           1       0.86      0.93      0.90     28049\n",
      "           2       0.82      0.63      0.71      6943\n",
      "           3       0.90      0.85      0.88     11429\n",
      "           4       0.84      0.82      0.83      9438\n",
      "           5       0.89      0.39      0.55      3006\n",
      "\n",
      "    accuracy                           0.87     83225\n",
      "   macro avg       0.87      0.76      0.80     83225\n",
      "weighted avg       0.87      0.87      0.86     83225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Naive Bayes classifier\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_count, y_train)\n",
    "nb_y_pred = nb_clf.predict(X_test_count)\n",
    "nb_report = classification_report(y_test, nb_y_pred)\n",
    "print(\"Naive Bayes Accuracy:\", nb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-24T17:58:31.156091Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Train and evaluate Logistic Regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "lr_y_pred = lr_clf.predict(X_test_tfidf)\n",
    "lr_report = classification_report(y_test, lr_y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"The best-model is logistic regression\")\n",
    "# Save the vectorizer and best model\n",
    "with open('tfidf_vectorizer_emotion.pkl', 'wb') as file:\n",
    "  pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Packing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open('best_emotion_model.pkl', 'wb') as file:\n",
    "  pickle.dump(lr_clf, file)\n",
    "\n",
    "# Function to predict emotion of a given text\n",
    "def predict_emotion(text):\n",
    "  cleaned_text = clean_text(text)\n",
    "  text_tfidf = vectorizer.transform([cleaned_text])\n",
    "  prediction = lr_clf.predict(text_tfidf)\n",
    "  emotions = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
    "  return emotions[prediction[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model Useage"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:01:55.342389Z",
     "start_time": "2024-11-24T18:01:51.491235Z"
    }
   },
   "source": [
    "# Example usage\n",
    "text = input(\"Enter text to predict emotion: \")\n",
    "# I like to play.\n",
    "emotion = predict_emotion(text)\n",
    "print(f'The predicted emotion is: {emotion}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted emotion is: joy\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
